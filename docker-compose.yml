version: '3.8'
services:
  ollama:
    build:
      context: 'https://raw.githubusercontent.com/iTeeLion/ollama_docker/main/Dockerfile'
      args:
        UID: ${UID}
        GID: ${GID}
    restart: unless-stopped
    ports:
      - '11434:11434'
    tty: true
    deploy:
      resources:
        reservations:
          devices:
              - driver: nvidia
                device_ids: ['0']
                capabilities: [compute, utility]
                
